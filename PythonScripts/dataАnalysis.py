import tensorflow as tf
import pandas as pd
import psycopg2
from ollama import chat
from ollama import ChatResponse


# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
DB_CONFIG = {
    'dbname': 'postgres',
    'user': 'postgres',
    'password': 'postgres',
    'host': 'localhost',
    'port': '5432',
}

def connect_db():
    """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        return None



def load_data_from_db():
    """–í—ã–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü"""
    conn = connect_db()
    if not conn:
        return None

    data = {}

    try:
        # –°–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        tables = [
            'users', 'projects', 'repositories', 'repo_branches',
            'git_users', 'repo_commits', 'repo_commit_parents',
            'repo_files', 'issues', 'pull_requests',
            'pull_request_reviewers', 'webhooks', 'service_accounts'
        ]


        for table in tables:
            query = f"SELECT * FROM {table}"
            data[table] = pd.read_sql_query(query, conn)

        conn.close()
        return data

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        conn.close()
        return None


def calculate_basic_statistics(data):
    """–†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TensorFlow"""
    stats = {}

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
    users_df = data['users']
    stats['total_users'] = tf.constant(len(users_df), dtype=tf.float32)
    stats['active_users'] = tf.constant(users_df['is_active'].sum(), dtype=tf.float32)
    stats['active_users_ratio'] = stats['active_users'] / stats['total_users']

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º
    projects_df = data['projects']
    stats['total_projects'] = tf.constant(len(projects_df), dtype=tf.float32)
    stats['public_projects'] = tf.constant(projects_df['is_public'].sum(), dtype=tf.float32)
    stats['favorite_projects'] = tf.constant(projects_df['is_favorite'].sum(), dtype=tf.float32)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º
    repos_df = data['repositories']
    stats['total_repositories'] = tf.constant(len(repos_df), dtype=tf.float32)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–º–º–∏—Ç–∞–º
    commits_df = data['repo_commits']
    stats['total_commits'] = tf.constant(len(commits_df), dtype=tf.float32)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–µ—Ç–∫–∞–º
    branches_df = data['repo_branches']
    stats['total_branches'] = tf.constant(len(branches_df), dtype=tf.float32)
    stats['protected_branches'] = tf.constant(branches_df['is_protected'].sum(), dtype=tf.float32)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ pull requests
    pr_df = data['pull_requests']
    stats['total_pr'] = tf.constant(len(pr_df), dtype=tf.float32)
    stats['merged_pr'] = tf.constant(pr_df['status'].str.lower().str.contains('merged').sum(), dtype=tf.float32)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ issues
    issues_df = data['issues']
    stats['total_issues'] = tf.constant(len(issues_df), dtype=tf.float32)

    return stats


def calculate_advanced_metrics(data):
    """–†–∞—Å—á–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TensorFlow"""
    metrics = {}

    # –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–º–º–∏—Ç–æ–≤
    commits_df = data['repo_commits']
    if not commits_df.empty:
        commits_df['created_at'] = pd.to_datetime(commits_df['created_at'])
        commit_dates = commits_df['created_at'].dt.date

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–∏—Ç–æ–≤ –ø–æ –¥–Ω—è–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º TensorFlow)
        unique_days = commit_dates.nunique()
        total_commits = len(commits_df)

        metrics['commits_per_day_avg'] = tf.constant(total_commits / unique_days if unique_days > 0 else 0,
                                                     dtype=tf.float32)

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–º–º–∏—Ç–æ–≤ –ø–æ –∞–≤—Ç–æ—Ä–∞–º
        author_commits = commits_df['author_id'].value_counts()
        metrics['commits_per_author_avg'] = tf.constant(author_commits.mean(), dtype=tf.float32)
        metrics['commits_per_author_std'] = tf.constant(author_commits.std(), dtype=tf.float32)

    # –ê–Ω–∞–ª–∏–∑ pull requests
    pr_df = data['pull_requests']
    if not pr_df.empty:
        pr_df['created_at'] = pd.to_datetime(pr_df['created_at'])
        pr_df['updated_at'] = pd.to_datetime(pr_df['updated_at'])

        # –í—Ä–µ–º—è –¥–æ –º–µ—Ä–∂–∞ PR
        merged_pr = pr_df[pr_df['status'].str.lower() == 'merged']
        if not merged_pr.empty:
            merge_times = (merged_pr['merged_at'] - merged_pr['created_at']).dt.total_seconds() / 3600  # –≤ —á–∞—Å–∞—Ö
            metrics['pr_merge_time_avg_hours'] = tf.constant(merge_times.mean(), dtype=tf.float32)

    return metrics


def create_tensorflow_model_for_analysis():
    """–°–æ–∑–¥–∞–Ω–∏–µ TensorFlow –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫"""
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(1, activation='linear')
    ])

    model.compile(optimizer='adam',
                  loss='mse',
                  metrics=['mae'])

    return model


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    data = load_data_from_db()

    if data is None:

        return


    stats = calculate_basic_statistics(data)
    metrics = calculate_advanced_metrics(data)


    model = create_tensorflow_model_for_analysis()


    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ content –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ Ollama
    content = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é GIT METRICS –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–æ —Å–≤–æ–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –æ—Ç–≤–µ—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 20 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n\n"

    content += "üìä –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò:\n"
    content += f"   –í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['total_users'].numpy():.0f}\n"
    content += f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['active_users'].numpy():.0f}\n"
    content += f"   –î–æ–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö: {stats['active_users_ratio'].numpy():.1%}\n\n"

    content += "üèóÔ∏è  –ü–†–û–ï–ö–¢–´:\n"
    content += f"   –í—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–æ–≤: {stats['total_projects'].numpy():.0f}\n"
    content += f"   –ü—É–±–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤: {stats['public_projects'].numpy():.0f}\n"
    content += f"   –ò–∑–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤: {stats['favorite_projects'].numpy():.0f}\n\n"

    content += "üìÅ –†–ï–ü–û–ó–ò–¢–û–†–ò–ò:\n"
    content += f"   –í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {stats['total_repositories'].numpy():.0f}\n"
    content += f"   –í—Å–µ–≥–æ –≤–µ—Ç–æ–∫: {stats['total_branches'].numpy():.0f}\n"
    content += f"   –ó–∞—â–∏—â–µ–Ω–Ω—ã—Ö –≤–µ—Ç–æ–∫: {stats['protected_branches'].numpy():.0f}\n\n"

    content += "üî® –ê–ö–¢–ò–í–ù–û–°–¢–¨:\n"
    content += f"   –í—Å–µ–≥–æ –∫–æ–º–º–∏—Ç–æ–≤: {stats['total_commits'].numpy():.0f}\n"
    content += f"   –í—Å–µ–≥–æ Pull Request'–æ–≤: {stats['total_pr'].numpy():.0f}\n"
    content += f"   –ú–µ—Ä–∂–µ–Ω—ã—Ö PR: {stats['merged_pr'].numpy():.0f}\n"
    content += f"   –í—Å–µ–≥–æ Issues: {stats['total_issues'].numpy():.0f}\n\n"

    content += "üìà –†–ê–°–®–ò–†–ï–ù–ù–´–ï –ú–ï–¢–†–ò–ö–ò:\n"
    if 'commits_per_day_avg' in metrics:
        content += f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–º–º–∏—Ç–æ–≤ –≤ –¥–µ–Ω—å: {metrics['commits_per_day_avg'].numpy():.2f}\n"
    if 'commits_per_author_avg' in metrics:
        content += f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–º–º–∏—Ç–æ–≤ –Ω–∞ –∞–≤—Ç–æ—Ä–∞: {metrics['commits_per_author_avg'].numpy():.2f}\n"
    if 'pr_merge_time_avg_hours' in metrics:
        content += f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –º–µ—Ä–∂–∞ PR (—á–∞—Å—ã): {metrics['pr_merge_time_avg_hours'].numpy():.2f}\n\n"

    content += "üßÆ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:\n"

    # –†–∞—Å—á–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫–æ–º–º–∏—Ç–æ–≤ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    commit_tensor = tf.constant([stats['total_commits'].numpy()], dtype=tf.float32)
    user_tensor = tf.constant([stats['total_users'].numpy()], dtype=tf.float32)
    commits_per_user = commit_tensor / user_tensor
    content += f"   –ö–æ–º–º–∏—Ç–æ–≤ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {commits_per_user.numpy()[0]:.2f}\n"

    # –†–∞—Å—á–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ PR
    if stats['total_pr'].numpy() > 0:
        pr_efficiency = stats['merged_pr'] / stats['total_pr']
        content += f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å PR: {pr_efficiency.numpy():.1%}\n"

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–º–∏—Ç–∞—Ö
    content += "\nüìã –ö–û–ú–ú–ò–¢–´ –° –°–û–û–ë–©–ï–ù–ò–Ø–ú–ò:\n"
    commits_df = data['repo_commits'].copy()
    git_users_df = data['git_users'].copy()
    repos_df = data['repositories'].copy()

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–º–º–∏—Ç–∞—Ö
    commits_with_authors = pd.merge(
        commits_df,
        git_users_df[['id', 'name']],
        left_on='author_id',
        right_on='id',
        how='left'
    )

    commits_full = pd.merge(
        commits_with_authors,
        repos_df[['id', 'name']],
        left_on='repository_id',
        right_on='id',
        how='left',
        suffixes=('_author', '_repo')
    )

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    commits_sorted = commits_full.sort_values('created_at', ascending=False)

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–≤–æ–¥–∏–º—ã—Ö –∫–æ–º–º–∏—Ç–æ–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    for idx, commit in commits_sorted.head(10).iterrows():  # –ø–µ—Ä–≤—ã–µ 10 –∫–æ–º–º–∏—Ç–æ–≤
        author_name = commit.get('name_author', 'Unknown')
        repo_name = commit.get('name_repo', 'Unknown')
        commit_hash = commit['hash'][:8] if pd.notna(commit['hash']) else 'Unknown'
        message = commit['message'] if pd.notna(commit['message']) else 'No message'

        commit_date = commit['created_at']
        if hasattr(commit_date, 'strftime'):
            commit_date = commit_date.strftime('%Y-%m-%d %H:%M')
        else:
            commit_date = str(commit_date)[:16]

        content += f"\nüë§ {author_name} | üìÇ {repo_name} | üïí {commit_date} | #{commit_hash}\n"
        content += f"   üí¨ {message}\n"

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π content –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama
    response: ChatResponse = chat(model='gemma3', messages=[
        {
            'role': 'user',
            'content': content,
        },
    ])
    return (response['message']['content'])

if __name__ == "__main__":
    main()

